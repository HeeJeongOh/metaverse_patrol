{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models ###\n",
    "# Support Vector machine\n",
    "from sklearn import svm\n",
    "# Naive Bayes\n",
    "import sklearn.naive_bayes as nb\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# random forest \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insult</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Comment\n",
       "Insult         \n",
       "0          2898\n",
       "1          1049"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Comment','Insult']].groupby('Insult').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 라벨과 댓글 쪼개기\n",
    "label, comments = train['Insult'],train['Comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Text Cleansing(lower case, removal)\\n2. Tokenization\\n3. Stemming(줄기어로 바꾸기)\\n4. Lemmatization(형태소 부석)\\n5. Stop words removal()\\n6. Rare words removal()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import re\n",
    "from re import sub\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "'''\n",
    "1. Text Cleansing(lower case, removal)\n",
    "2. Tokenization\n",
    "3. Stemming(줄기어로 바꾸기)\n",
    "4. Lemmatization(형태소 부석)\n",
    "5. Stop words removal()\n",
    "6. Rare words removal()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(x):\n",
    "    #st = LancasterStemmer()\n",
    "    st = WordNetLemmatizer()\n",
    "    words=x.strip().split()\n",
    "    st3=SnowballStemmer(\"english\")\n",
    "    return [st3.stem(st.lemmatize(x)) for x in words]\n",
    "\n",
    "def remove_special_char(x):\n",
    "    # this will replace all punctuations with spaces\n",
    "    punc = string.punctuation.replace(\"-\", \"\")\n",
    "    punc = punc.replace(\"'\", \"\")\n",
    "    pat= r\"[{}]\".format(punc)\n",
    "    x=re.sub(pat, \" \", x)\n",
    "    \n",
    "    # this will replace all digits with None\n",
    "    x=re.sub(pattern=r\"\\d\", repl=r\" \", string=x)\n",
    "    \n",
    "    # this will strip extra white spaces\n",
    "    return \" \".join( i for i in stemming(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "comments=comments.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"i really don\\'t understand your point.\\\\xa0 it seems that you are mixing apples and oranges.\"',\n",
       " \"i realli don't understand your point \\\\xa it seem that you are mix appl and orang\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2, 3, 4\n",
    "comments_tran = comments.apply(remove_special_char)\n",
    "comments.iloc[1], comments_tran.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set, 179)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 5, 6\n",
    "stopWords = set(stopwords.words('english'))\n",
    "type(stopWords), len(stopWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3947, 11775)\n"
     ]
    }
   ],
   "source": [
    "tf = text.TfidfVectorizer(stop_words=list(stopWords), ngram_range=(1, 1))\n",
    "X = tf.fit_transform(comments_tran)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=list((tf.vocabulary_).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# to split data\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "import sklearn.feature_extraction.text as text\n",
    "\n",
    "### models ###\n",
    "# Support Vector machine\n",
    "from sklearn import svm\n",
    "# Naive Bayes\n",
    "import sklearn.naive_bayes as nb\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# random forest \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3157, 11775), (790, 11775))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_val,label_train, label_val) = train_test_split(X, label, test_size=.2)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear classfication model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LR():\n",
    "    # creating classifier\n",
    "    clf = LogisticRegression(tol=1e-8, penalty='l2', C=2)\n",
    "    # training classifier\n",
    "    clf.fit(X_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(X_val)\n",
    "    return (clf.predict(X_val),p)\n",
    "\n",
    "def model_SVM():\n",
    "    # creating classifier\n",
    "    clf = svm.LinearSVC(penalty='l2', loss='squared_hinge',tol=1e-8)\n",
    "    # training classifier\n",
    "    clf.fit(X_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    return clf.predict(X_val)\n",
    "\n",
    "# Bernoulli Naive Baiyes\n",
    "def model_BernoulliNB():\n",
    "    # creating classifier\n",
    "    clf = nb.BernoulliNB(alpha=1.0, binarize=0.0)\n",
    "    # training classifier\n",
    "    clf.fit(X_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(X_val)\n",
    "    return (clf.predict(X_val),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-linear classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "def model_RF():\n",
    "    # creating classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    # training classifier\n",
    "    clf.fit(X_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(X_val)\n",
    "    return (clf.predict(X_val),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_DT():\n",
    "    # creating classifier\n",
    "    clf = DecisionTreeClassifier(max_depth=100)\n",
    "    # training classifier\n",
    "    clf.fit(X_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(X_val)\n",
    "    return (clf.predict(X_val),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC score\n",
    "from sklearn.metrics import roc_auc_score as auc_score\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model,label_test):\n",
    "    #accuracy=np.mean(model == label_test)\n",
    "    #print(\"%.4f\"%np.mean(model == label_test))\n",
    "    # confusion matrix:\n",
    "    cm = confusion_matrix(label_test, model, labels=None, sample_weight=None)\n",
    "    tp, fn, fp, tn = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    precision= float(tp)/(tp+fp)\n",
    "    recall =  float(tp)/(tp+tn)\n",
    "    accuracy = np.mean(model == label_test)\n",
    "    print_results (precision, recall, accuracy)\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def print_results (precision, recall, accuracy):\n",
    "    banner = \"Here is the classification report\"\n",
    "    print ('\\n',banner)\n",
    "    print ('=' * len(banner))\n",
    "    print ('{0:10s} {1:.1f}'.format('Precision',precision*100))\n",
    "    print ('{0:10s} {1:.1f}'.format('Recall',recall*100))\n",
    "    print ('{0:10s} {1:.1f}'.format('Accuracy',accuracy*100))\n",
    "    \n",
    "    \n",
    "    #print(\"*****PRECISION****\")\n",
    "    #print(\"%.4f\"%(tp/(tp+fp)))\n",
    "    #print(\"*****RECALL****\")\n",
    "    #print(\"%.4f\"%(tp/(tp+tn)))\n",
    "    #return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  82.6\n",
      "Recall     87.0\n",
      "Accuracy   82.0\n",
      "AUC Score  0.9\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "clf_LR, p = model_LR()\n",
    "# model evaluation\n",
    "acc_LR = model_evaluation(clf_LR, label_val)\n",
    "\n",
    "print('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.svm._classes.LinearSVC'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  86.5\n",
      "Recall     82.5\n",
      "Accuracy   84.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hee/git/metaverse_patrol/metaverse/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "clf_SVM = model_SVM()\n",
    "# model evaluation\n",
    "acc_SVM = model_evaluation(clf_SVM, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  78.4\n",
      "Recall     92.3\n",
      "Accuracy   77.5\n",
      "AUC Score  81.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model prediction\n",
    "clf_NB,p=model_BernoulliNB()\n",
    "# model evaluation\n",
    "acc_NB = model_evaluation(clf_NB, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  81.4\n",
      "Recall     87.7\n",
      "Accuracy   79.5\n",
      "AUC Score  83.5\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "clf_RF,p=model_RF()\n",
    "# model evaluation\n",
    "acc_RF = model_evaluation(clf_RF, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  84.2\n",
      "Recall     81.8\n",
      "Accuracy   76.6\n",
      "AUC Score  66.4\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "clf_DT,p=model_DT()\n",
    "# model evaluation\n",
    "acc_DT = model_evaluation(clf_DT, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for all Models\n",
    "accuracy_normal=[acc_LR, acc_SVM, acc_NB, acc_RF, acc_DT]\n",
    "accuracy_normal=[('{0:2f}'.format(i*100)) for i in accuracy_normal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression       82.025316\n",
      "Support Vector Machine    84.430380\n",
      "Naive Bayes               77.468354\n",
      "Random Forest             79.493671\n",
      "Decision Tree             76.582278\n"
     ]
    }
   ],
   "source": [
    "models = ['Logistic Regression', 'Support Vector Machine', 'Naive Bayes', 'Random Forest', 'Decision Tree']\n",
    "for name, acc in zip(models, accuracy_normal):\n",
    "    print('{0:<25s} {1:>5s}'.format(name, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
